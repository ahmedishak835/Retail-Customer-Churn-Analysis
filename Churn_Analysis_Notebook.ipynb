import pandas as pd
import numpy as np
import random

# Set seed for reproducibility
np.random.seed(42)

# Configuration
num_customers = 1000

# 1. Generate Base Data
data = {
    'customer_id': [f'CUST-{i:04d}' for i in range(1, num_customers + 1)],
    'age': np.random.randint(18, 75, size=num_customers),
    'gender': np.random.choice(['M', 'F', 'Non-Binary'], size=num_customers),
    'tenure_months': np.random.randint(1, 72, size=num_customers),
    'monthly_charges': np.random.uniform(15.0, 120.0, size=num_customers).round(2),
    'total_charges': 0, # Will calculate this
    'support_tickets': np.random.poisson(lam=2, size=num_customers),
    'contract_type': np.random.choice(['Month-to-Month', 'One Year', 'Two Year'], size=num_customers, p=[0.5, 0.3, 0.2]),
    'churn': np.random.choice([0, 1], size=num_customers, p=[0.7, 0.3])
}

df = pd.DataFrame(data)

# 2. Add realistic logic (Total Charges = Monthly * Tenure)
df['total_charges'] = (df['monthly_charges'] * df['tenure_months']).round(2)

# 3. Inject "Dirty Data" (Junior consultants need to show they can clean data!)
# Add some missing values in 'total_charges'
for _ in range(25):
    df.loc[random.randint(0, num_customers-1), 'total_charges'] = np.nan

# 4. Save to CSV for the SQL phase
df.to_csv('sparta_retail_data.csv', index=False)

print("✅ Dataset 'sparta_retail_data.csv' created successfully!")
df.head()

import sqlite3

# Create an in-memory SQL database
conn = sqlite3.connect('sparta_consulting.db')

# Load our pandas dataframe into a SQL table
df.to_sql('customers', conn, if_exists='replace', index=False)

print("✅ SQL Table 'customers' is ready for querying!")

# We use pd.read_sql to run a SQL query and see the results as a nice table
query = """
SELECT 
    contract_type, 
    COUNT(customer_id) AS total_customers,
    SUM(churn) AS churned_customers,
    ROUND(AVG(support_tickets), 2) AS avg_support_tickets,
    ROUND(SUM(monthly_charges), 2) AS lost_monthly_revenue
FROM customers
WHERE churn = 1
GROUP BY contract_type
ORDER BY lost_monthly_revenue DESC;
"""

sql_results = pd.read_sql(query, conn)
sql_results

# Check how many missing values we have before fixing
missing_before = df['total_charges'].isnull().sum()
print(f"Missing values before cleaning: {missing_before}")

# Fix: Fill missing total_charges by multiplying Monthly Charges by Tenure
df['total_charges'] = df['total_charges'].fillna(df['monthly_charges'] * df['tenure_months'])

# Check again
missing_after = df['total_charges'].isnull().sum()
print(f"Missing values after cleaning: {missing_after}")
print("✅ Data Integrity restored.")

import seaborn as sns
import matplotlib.pyplot as plt

# Set the visual style
sns.set_theme(style="whitegrid")

plt.figure(figsize=(10, 6))
# Create a bar plot showing Churn Rate across Contract Types
sns.barplot(x='contract_type', y='churn', data=df, palette='viridis', ci=None)

plt.title('Churn Rate by Contract Type', fontsize=15)
plt.ylabel('Percentage of Customers Leaving')
plt.xlabel('Contract Type')
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

# Calculate the correlation matrix
# We only look at numbers (numeric_only=True)
corr = df.corr(numeric_only=True)

# Create the heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)

plt.title('Feature Correlation: What drives Churn?', fontsize=16)
plt.show()
